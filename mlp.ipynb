{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q13-chJic4Kz",
        "outputId": "3ab50e72-0739-46a5-c521-c6a8b97a853a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.0\n",
            "  Downloading d2l-1.0.0-py3-none-any.whl.metadata (524 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l==1.0.0)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l==1.0.0)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.0)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l==1.0.0)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l==1.0.0)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.0)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.0) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.0)\n",
            "  Downloading qtconsole-5.6.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.0) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.0) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.0) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (10.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.0)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.0) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.0) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.0) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.0) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.0) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.0) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.0) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.0) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.0) (2.18.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (3.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.0) (1.1.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.0)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.0) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.0) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.0) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.0) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.0) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.0) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.0) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.0) (1.2.2)\n",
            "Downloading d2l-1.0.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.4\n",
            "    Uninstalling pyparsing-3.1.4:\n",
            "      Successfully uninstalled pyparsing-3.1.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.0 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.0 qtpy-2.4.1 requests-2.31.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "3058ddb844874860adc37dc727a8fbf0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l"
      ],
      "metadata": {
        "id": "3GQjw22jc_mo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "kXxa_3jOdQJv",
        "outputId": "99ec44a8-e733-4feb-fce0-19b1117e7d35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e05f2611-b001-4e95-bb6e-7ded71dc5316\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e05f2611-b001-4e95-bb6e-7ded71dc5316\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test (1).csv\n",
            "Saving train.csv to train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('train.csv')\n",
        "df2 = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "jaiYTvwjePeW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# İlk beş satırı görüntüleme\n",
        "print(\"Train Veri Seti - İlk Beş Satır:\")\n",
        "print(df1.head())\n",
        "\n",
        "print(\"\\nTest Veri Seti - İlk Beş Satır:\")\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSqED6H7elPM",
        "outputId": "614d45f5-8c22-472d-a03f-035b12db17ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Veri Seti - İlk Beş Satır:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Test Veri Seti - İlk Beş Satır:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Veri Setindeki toplam veri sayısı: {len(df1)}\")\n",
        "\n",
        "print(f\"Test Veri Setindeki toplam veri sayısı: {len(df2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfi_NOR-e6co",
        "outputId": "95993e61-da4b-4473-f42c-986e821801ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Veri Setindeki toplam veri sayısı: 1460\n",
            "Test Veri Setindeki toplam veri sayısı: 1459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KaggleHouse:\n",
        "    def __init__(self, batch_size, df1, df2):\n",
        "        self.batch_size = batch_size\n",
        "        self.df1 = df1\n",
        "        self.df2 = df2\n",
        "\n",
        "        # Verilerin ilk beş satırını görüntüleme\n",
        "        print(\"Train Veri Seti - İlk Beş Satır:\")\n",
        "        print(self.df1.head())\n",
        "\n",
        "        print(\"\\nTest Veri Seti - İlk Beş Satır:\")\n",
        "        print(self.df2.head())\n",
        "\n",
        "        # Veri setlerinin boyutlarını yazdırma\n",
        "        print(f\"\\nTrain Veri Setindeki toplam veri sayısı: {len(self.df1)}\")\n",
        "        print(f\"Test Veri Setindeki toplam veri sayısı: {len(self.df2)}\")\n",
        "\n",
        "# Sınıfın kullanımı\n",
        "house = KaggleHouse(batch_size=32, df1=df1, df2=df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgDKup4IfQ4p",
        "outputId": "4b5d5315-955a-4d6f-8f3b-5685f1c26efe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Veri Seti - İlk Beş Satır:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Test Veri Seti - İlk Beş Satır:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "\n",
            "Train Veri Setindeki toplam veri sayısı: 1460\n",
            "Test Veri Setindeki toplam veri sayısı: 1459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KaggleHouse sınıfını yukarıda tanımladığımız gibi kullanıyoruz\n",
        "class KaggleHouse:\n",
        "    def __init__(self, batch_size, df1, df2):\n",
        "        self.batch_size = batch_size\n",
        "        self.raw_train = df1  # Eğitim veri seti\n",
        "        self.raw_val = df2    # Test veri seti\n",
        "\n",
        "        # Veri setlerinin boyutlarını görüntüleme\n",
        "        print(\"Train Veri Seti - İlk Beş Satır:\")\n",
        "        print(self.raw_train.head())\n",
        "\n",
        "        print(\"\\nTest Veri Seti - İlk Beş Satır:\")\n",
        "        print(self.raw_val.head())\n",
        "\n",
        "# Sınıfı başlatalım\n",
        "data = KaggleHouse(batch_size=64, df1=df1, df2=df2)\n",
        "\n",
        "# Eğitim ve test veri setlerinin boyutlarını yazdıralım\n",
        "print(f\"Train veri seti boyutları: {data.raw_train.shape}\")\n",
        "print(f\"Test veri seti boyutları: {data.raw_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkHe5v5jh7LF",
        "outputId": "782de2c5-45c3-442f-c00c-6dac55f7dfb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Veri Seti - İlk Beş Satır:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Test Veri Seti - İlk Beş Satır:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "Train veri seti boyutları: (1460, 81)\n",
            "Test veri seti boyutları: (1459, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.raw_train.iloc[:4, [0, 1, 2, 3, -3, -2, -1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsGh01FpiVYp",
        "outputId": "97d87a62-a066-4494-e666-2d80c762e221"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
            "0   1          60       RL         65.0       WD        Normal     208500\n",
            "1   2          20       RL         80.0       WD        Normal     181500\n",
            "2   3          60       RL         68.0       WD        Normal     223500\n",
            "3   4          70       RL         60.0       WD       Abnorml     140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(KaggleHouse)\n",
        "def preprocess(self):\n",
        "    # Etiket sütunu\n",
        "    label = 'SalePrice'\n",
        "\n",
        "    # Id ve etiket sütunlarını kaldırıyoruz\n",
        "    features = pd.concat(\n",
        "        (self.raw_train.drop(columns=['Id', label]),\n",
        "         self.raw_val.drop(columns=['Id'])))\n",
        "\n",
        "    # Sayısal sütunları normalleştiriyoruz\n",
        "    numeric_features = features.dtypes[features.dtypes != 'object'].index\n",
        "    features[numeric_features] = features[numeric_features].apply(\n",
        "        lambda x: (x - x.mean()) / (x.std()))\n",
        "\n",
        "    # Eksik sayısal değerleri 0 ile dolduruyoruz\n",
        "    features[numeric_features] = features[numeric_features].fillna(0)\n",
        "\n",
        "    # Kategorik değişkenleri one-hot encoding'e çeviriyoruz\n",
        "    features = pd.get_dummies(features, dummy_na=True)\n",
        "\n",
        "    # İşlenmiş verileri kaydediyoruz\n",
        "    self.train = features[:self.raw_train.shape[0]].copy()\n",
        "    self.train[label] = self.raw_train[label]\n",
        "    self.val = features[self.raw_train.shape[0]:].copy()\n",
        "\n",
        "# KaggleHouse sınıfı üzerinde çalıştırma\n",
        "data = KaggleHouse(batch_size=64, df1=df1, df2=df2)\n",
        "data.preprocess()\n",
        "\n",
        "# İşlenmiş veri setlerinin boyutlarını yazdıralım\n",
        "print(f\"İşlenmiş Train veri seti boyutları: {data.train.shape}\")\n",
        "print(f\"İşlenmiş Test veri seti boyutları: {data.val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvsfVysBi2dq",
        "outputId": "c1293e04-fed7-4dc3-bab3-a65fe2a38490"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Veri Seti - İlk Beş Satır:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Test Veri Seti - İlk Beş Satır:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "İşlenmiş Train veri seti boyutları: (1460, 331)\n",
            "İşlenmiş Test veri seti boyutları: (1459, 330)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "def get_dataloader(df, train=True):\n",
        "    label = 'SalePrice'\n",
        "\n",
        "    # Eğitim veri setini kullanıyoruz\n",
        "    data = df1 if train else df2\n",
        "\n",
        "    # Eğer etiket sütunu yoksa (test seti gibi) işlem yapmıyoruz\n",
        "    if train and label not in data.columns:\n",
        "        return None\n",
        "\n",
        "    # Kategorik ve sayısal sütunları ayırma\n",
        "    numeric_features = data.select_dtypes(include=['number']).drop(columns=[label]).columns if train else data.select_dtypes(include=['number']).columns\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # One-hot encoding ile kategorik sütunları genişletme\n",
        "    data = pd.get_dummies(data, columns=categorical_features, dummy_na=True)\n",
        "\n",
        "    # Pandas DataFrame'den TensorFlow tensor'larına dönüştürme fonksiyonu\n",
        "    get_tensor = lambda x: tf.constant(x.values.astype(float), dtype=tf.float32)\n",
        "\n",
        "    # Özellikleri ve hedef değişkeni tensor'lara çeviriyoruz\n",
        "    if train:\n",
        "        tensors = (get_tensor(data[numeric_features]),  # X (numerik veriler)\n",
        "                   tf.reshape(tf.math.log(get_tensor(data[label])), (-1, 1)))  # Y (logaritmik fiyatlar)\n",
        "    else:\n",
        "        tensors = get_tensor(data[numeric_features])  # Test setinde Y yok, sadece X\n",
        "\n",
        "    return tensors\n",
        "\n",
        "# Eğitim verisini tensor olarak alalım\n",
        "train_tensors = get_dataloader(df1, train=True)\n",
        "print(\"Eğitim veri seti tensor boyutları:\")\n",
        "print(f\"Özellikler (X): {train_tensors[0].shape}, Hedefler (Y): {train_tensors[1].shape}\")\n",
        "\n",
        "# Test verisini tensor olarak alalım\n",
        "test_tensors = get_dataloader(df2, train=False)\n",
        "if test_tensors is not None:\n",
        "    print(\"Test veri seti tensor boyutları:\")\n",
        "    print(f\"Özellikler (X): {test_tensors.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsWyrRNejc2i",
        "outputId": "80af14e8-9039-4bb7-913a-0e758201046c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim veri seti tensor boyutları:\n",
            "Özellikler (X): (1460, 37), Hedefler (Y): (1460, 1)\n",
            "Test veri seti tensor boyutları:\n",
            "Özellikler (X): (1459, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# İşlenmiş veri setlerini CSV formatında kaydediyoruz\n",
        "data.train.to_csv('processed_train.csv', index=False)\n",
        "data.val.to_csv('processed_test.csv', index=False)\n"
      ],
      "metadata": {
        "id": "J65N0u344qre"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "WRNxhK_YbA41"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold çapraz doğrulama parametreleri\n",
        "n_splits = 5  # 5 katlı çapraz doğrulama\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# İşlenmiş train veri setinden etiketleri ayırıyoruz\n",
        "X = data.train.drop(columns=['SalePrice'])\n",
        "y = data.train['SalePrice']\n",
        "\n",
        "# Logaritmik dönüşümü burada da uyguluyoruz (logarithmic transformation of the labels)\n",
        "y = np.log(y)\n"
      ],
      "metadata": {
        "id": "8fMaix7Wb6PV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1)  # Tek hedef değişken (SalePrice)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hJEUQyVFb8T3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validasyon kayıplarını depolayacağımız liste\n",
        "val_losses = []\n",
        "\n",
        "# K-Fold çapraz doğrulama\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "    print(f'Fold {fold+1}/{n_splits}')\n",
        "\n",
        "    # Eğitim ve validasyon verilerini ayırma\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Modeli oluşturma\n",
        "    model = build_model(input_shape=X_train.shape[1])\n",
        "\n",
        "    # Modeli eğitme\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
        "\n",
        "    # Her fold için validasyon kaybını depoluyoruz\n",
        "    val_loss = model.evaluate(X_val, y_val, verbose=0)[0]\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f'Fold {fold+1} Validation Loss: {val_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfTiO8Z9b_jI",
        "outputId": "a3058aa3-a5f4-4496-a933-ebae18b044aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Validation Loss: 0.0621090866625309\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Validation Loss: 0.1305965930223465\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Validation Loss: 0.16426315903663635\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Validation Loss: 0.07688836008310318\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Validation Loss: 0.05759743973612785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tüm fold'lar için ortalama validasyon kaybını hesaplayalım\n",
        "mean_val_loss = np.mean(val_losses)\n",
        "print(f'\\nOrtalama Validation Loss: {mean_val_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1TiQl8wcBvb",
        "outputId": "252106ce-4fd3-472c-ecd5-9743901f1752"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ortalama Validation Loss: 0.09829092770814896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Son modelimizi tüm eğitim verisiyle oluşturuyoruz\n",
        "final_model = build_model(input_shape=X.shape[1])\n",
        "\n",
        "# Modeli tüm eğitim verisiyle eğitiyoruz\n",
        "final_model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9G4jF48cHmT",
        "outputId": "8af877d6-dc12-4d2e-f019-2984f7c093df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 86.0321 - mae: 8.3836\n",
            "Epoch 2/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8993 - mae: 0.7566\n",
            "Epoch 3/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1960 - mae: 0.3236\n",
            "Epoch 4/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1220 - mae: 0.2598\n",
            "Epoch 5/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0855 - mae: 0.2221\n",
            "Epoch 6/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0610 - mae: 0.1865\n",
            "Epoch 7/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0471 - mae: 0.1623\n",
            "Epoch 8/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0423 - mae: 0.1486\n",
            "Epoch 9/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0294 - mae: 0.1286\n",
            "Epoch 10/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0261 - mae: 0.1221\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7be8117ef310>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verisi üzerinde tahmin yapıyoruz\n",
        "test_predictions = final_model.predict(data.val)\n",
        "\n",
        "# Logaritmik dönüşümden geri döndürme (exp ile log'dan çıkıyoruz)\n",
        "predicted_prices = np.exp(test_predictions).flatten()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT7B1aZncTHt",
        "outputId": "da5168d5-4fc7-44d9-949d-27b971c12a41"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test ID dosyasını yükleyin\n",
        "test_ids = pd.read_csv('test.csv')  # ID'lerinizi içeren dosya\n"
      ],
      "metadata": {
        "id": "4kcdyXencWU-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test ID'leri ile tahminleri birleştiriyoruz\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_ids['Id'],  # Yüklediğiniz test ID dosyasından gelen ID'ler\n",
        "    'SalePrice': predicted_prices  # Tahmin edilen satış fiyatları\n",
        "})\n",
        "\n",
        "# Tahmin sonuçlarını kaydediyoruz\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "cpJJwhrica2V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjSl56t9c1AI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}